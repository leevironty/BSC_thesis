@article{johnson2007, % "p-arvot" bayesläisille malleille
    author = "Johnson, Valen E.",
    doi = "10.1214/07-BA229",
    fjournal = "Bayesian Analysis",
    journal = "Bayesian Anal.",
    month = "12",
    number = "4",
    pages = "719--733",
    publisher = "International Society for Bayesian Analysis",
    title = "Bayesian model assessment using pivotal quantities",
    url = "https://doi.org/10.1214/07-BA229",
    volume = "2",
    year = "2007"
}


@Article{Vehtari2017, % LOO estimointi PSIS-LOO(+) menetelmällä
    author={Vehtari, Aki
    and Gelman, Andrew
    and Gabry, Jonah},
    title={Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC},
    journal={Statistics and Computing},
    year={2017},
    month={Sep},
    day={01},
    volume={27},
    number={5},
    pages={1413-1432},
    abstract={Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
    issn={1573-1375},
    doi={10.1007/s11222-016-9696-4},
    url={https://doi.org/10.1007/s11222-016-9696-4}
}


http://users.jyu.fi/~hemipu/itms/Spiegelhalter%20et%20al.%202002%20JRSSb%20DIC.pdf
Bayesian measures of model complexity and fit

https://link.springer.com/content/pdf/10.1007/s11222-016-9649-y.pdf
Comparison of Bayesian predictive methods for model selection
# Good shit

https://arxiv.org/pdf/1307.5928.pdf
Understanding predictive information criteria for Bayesian models

https://arxiv.org/pdf/0912.0902.pdf
Making and Evaluating Point Forecasts
# pohdintaa metriikoista ja niiden valinnoista

http://www.jmlr.org/papers/volume14/watanabe13a/watanabe13a.pdf
WAIC

http://www.jmlr.org/papers/volume11/watanabe10a/watanabe10a.pdf
WAIC asymptoottisuus

https://link-springer-com.libproxy.aalto.fi/content/pdf/10.1007/s11222-016-9696-4.pdf
PSIS
# Hemmetin hyviä plotteja, tästä inspistä

https://arxiv.org/pdf/1507.02646.pdf
PSIS kuvaus
# Vähän ohi aiheen, mutta plotti-inspiraatiota?

https://projecteuclid.org/download/pdfview_1/euclid.ssu/1356628931
Survey
# Aika jööti, mutta varmaan tapa osoittaa "industry standard" menetelmät


http://www.stat.columbia.edu/~gelman/research/published/bayes_R2_v3.pdf
R^2 bayeslaisille malleille


https://arxiv.org/pdf/1701.02434.pdf
HMC concept


https://arxiv.org/pdf/1111.4246.pdf
NUTS


https://arxiv.org/pdf/1604.00695.pdf
HMC disgnostiikka


https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2680310/pdf/nihms94914.pdf
Bayesian Variable Selection and Computation for GeneralizedLinear Models with Conjugate Priors
# Ei välttämättä just tähän, mut mahdollisesti hyvä lisä


