\documentclass[english, 12pt, a4paper, sci, utf8, a-1b, online]{aaltothesis}
% testi
\usepackage{graphicx}

\usepackage{amsfonts, amssymb, amsbsy, amsmath}
\usepackage[english, finnish]{babel}
\usepackage{natbib}

\usepackage{csvsimple}

\usepackage{caption}
\usepackage{subcaption}

\newpage

\bibliographystyle{plainnat}
\setcitestyle{authoryear,open={(},close={)}}




\degreeprogram{Engineering Physics and Mathematics}

\major{Mathematics and Systems Sciences}

\code{SCI3029}

\univdegree{BSc}


\thesisauthor{Leevi Rönty}

\thesistitle{Bayesian model validation metrics in retail datasets}
%\thesistitle[Opinnäytteen otsikko]{Opinnäyteen\\ otsikko}
%%

%%
\place{Espoo}
%%



\date{14.10.2020}

\supervisor{Prof.\ Fabricio Oliveira}

\advisor{DSc\ (Tech.) Mikko Ervasti}
\advisor{DSc\ (Tech.) Paavo Niskala} % TODO: checkaa voiko tähän lisätä kahta näin

\uselogo{aaltoBlue}{''}


\keywords{Bayesian models\spc model validation\spc
	information criterion\spc Facebook Prophet}

\thesisabstract{
Tiivistelmässä on lyhyt selvitys kirjoituksen tärkeimmästä sisällöstä: mitä ja
miten on tutkittu, sekä mitä tuloksia on saatu. Tämän opinnäytteen 
tiivistelmäteksti kirjoitetaan opinnäytteen luettavan osan
lomakkeen lisäksi myös pdf-tiedoston metadataan. Kirjoita tähän metadataan
kirjoitettavaa teksti. Metadatatekstissa ei saa olla erikoismerkkejä,
rivinvaiho- tai kappaleenjakomerkkiä, joten näitä merkkeja ei saa käyttää tässä.
Jos tiivistelmäsi ei sisällä erikoimerkkejä eikä kaipaa kappaleenjakoa, voit
hyödynttää makroa abstracttext luodessasi lomakkeen tiivistelmää (katso
kommentti alla). Metadatatiivistelmatekstin on muuten oltava sama kuin
lomakkeessa oleva teksti.
}

\copyrighttext{Copyright \noexpand\copyright\ \number\year\ \ThesisAuthor}
{Copyright \copyright{} \number\year{} \ThesisAuthor 
\\\\The document can be stored and made available to the public on the open internet pages of Aalto University.\\
All other rights are reserved.
}


%% Kaikki mikä paperille tulostuu, on tämän jälkeen
\begin{document}

\makecoverpage{}


\makecopyrightpage{}


\begin{abstractpage}[english]
Your abstract in English. Keep the abstract short. The abstract explains your
research topic, the methods you have used, and the results you obtained.
\end{abstractpage}

\newpage


\thesistitle{Bayeslaisten mallien validointi vähittäismyynnin aineistoissa}
\degreeprogram{Teknillinen fysiikka ja matematiikka}
\major{Matematiikka ja systeemitieteet}
\advisor{TkT Mikko Ervasti}
\advisor{TkT Paavo Niskala}
\keywords{Bayeslaiset mallit\spc mallin validointi\spc
	informaatiokriteeri\spc Facebook Prophet}

\begin{abstractpage}[finnish]
Tiivistelmässä on lyhyt selvitys kirjoituksen tärkeimmästä sisällöstä: mitä ja
miten on tutkittu, sekä mitä tuloksia on saatu.

Tämän opinnäytteen tiivistelmäteksti kirjoitetaan opinnäytteen luettavan osan 
lomakkeen lisäksi myös pdf-tiedoston metadataan 
$\backslash$thesisabstract-makron avulla (kasto yllä). Kirjoita tähän
luettavaan tiivistelmälomakkeeseen menevä teksti. Tässä saa olla erikoismerkkejä
kuten kreikkalaiset kirjaimet ja rivinvaiho- ja kappaleenjakomerkit. Tämän
tekstin on muuten oltava sama kuin metedatatiivistelmän teksti.

Jos tiivistelmäsi ei sisällä erikoimerkkejä eikä kaipaa kappaleenjakoa, voit
hyödynttää makroa $\backslash$abstracttext luodessasi lomakkeen tiivistelmää
(katso kommentti alla).

\end{abstractpage}

%% Sisällysluettelo
\thesistableofcontents

\cleardoublepage

%% Leipäteksti alkaa
%%
\section{Introduction}

%Modelling and forecasting of sales timeseries helps in deciding marketing investments
%Company (Sellforte) makes lots of forecasts to customers
%Validation of used models is a critical part of the process and a subject of ongoing developement in company
%Cross validation is best practice, but it’s not always feasible to do
%Data from a short time frame or expensive fitting of models
%Information criterions aim to estimate fit to out-of-sample data

%%% Motivaatio ja tausta
%- Yritykset laativat paljon ennusteita
%- Mallien validointi on oleellinen osa prosessia
%- Bayeslaisten mallien validointi on kuitenkin suhteellisen uusi asia


%%% Haasteet ja kirjallisuus
%- Bayeslaisten mallien validoinnin nykytila on "unsatisfactory"
%- Kuhunkin käytetyimmistä menetelmistä liittyy ongelmia
%- Entä jos sakkofunktiona MAPE?

%%% Mitä tehdään
%- Mallinnetaan myyntiä Prophetilla
%- Implementoidaan IC:t prophetille
%- Vertaillaan tuloksia 'ad-hoc' -menetelmiin

%%% Työn rakenne
%- Ei välttis pakollinen



% kommentti: too vague, try to focus on the need for being able to compare the performance of models in a systematic way
% oliskohan nyt parempi?
Businesses need forecasting to succeed. Correctly forecasting demand for goods is essential for any retail business, 
as shortages can cause loss of sales. As companies collect more and more data, 
the possibilities of forecastable subjects and possible features increase dramatically. However, one can not just
include more features in the model and expect it to perform well. Also, not all models are suitable for all 
forecasting tasks. The amount of possible models is endless, but most of them will perform poorly. To find the useful ones,
we must be able to measure the goodness of a model. Being able to objectively compare models allows for systematic 
approaches of model selection to be adopted.

Model validation is an integral part of a robust modelling framework. Bayesian models are a relatively novel
model type, which has gained considerable popularity in recent years, as computational power of modern computers 
has kept rising. As a relatively new method, not too many validation metrics have been proposed with these kinds
of models in mind.

The current state of model validation for bayesian models can be described as "unsatisfactory". Information
criteria that try to predict out of sample fitness can have strong biases, and some may not take into consideration
the nature of bayesian models and distributions of parameters. Cross validation can be extremely computationally 
intensive. Also, most information criteria are based on a loss function proportional to the root mean square of errors,
but that may not always be the most useful function to optimize for. In some businesses the consequences of errors
in forecasts can be described better with the mean absolute percentage error. All in all there does not
exist a clearly better method for solving all bayesian model validation problems.

In this thesis we will model sales time series of some Wallmart stores in the United States. We will be using 
the Facebook's Prophet modelling framework. It consists of a flexible bayesian model which can be customized 
to fit a wide range of possible time series modelling tasks. We will implement some information criteria 
for the model and compare it to more ad-hoc methods for model validation. 



%\section{Aikaisempi tutkimus}
\section{Background}

%Tässä osassa selvitetään, mitä tutkimuksen kohteena olevasta aiheesta tiedetään
%entuudestaan. Selvityksen tulee kattaa tasapainoisesti koko tutkimuskenttä. 

%Kun opinnäytetyötä kirjoitetaan, on noudatettava ohjeita, jotka koskevat
%opinnäytteen rakennetta, käytäntöjä, muotoseikkoja sekä ulkoasua. Esitellään
%näitä ohjeita tarkemmin.

%% Osan hienojaottelua alaosiin, eikä välttämättä edes tarpeen, tässä vain
%% esimerkkinä. Käytä harkintasi mukaan osan jaottelua, joskus alaotsikot
%% selventävät asioita ja joskus vain sirpaloittavat tarpeettomasti tekstiä.
%%  Jaottelu menee seuraavasti:
%% \section{osan otsikko} 
%% \subsection{alaotsikko}
%% \subsubsection{ala-alaotsikko}
%% Tätä pitemälle ei pidä jaotella. 
%%
%% Three levels of hierarchy in sectioning should be enough



%Työn tausta:
%– Esitellään, mitä kirjallisuudessa on aiemmin esitetty
%– Formaatti: ”Henkilöt X tutkivat asiaa Y ja tulivat siihen
%johtopäätökseen, että Z”
%– Oman työn kontribuutiota voi tässä osiossa peilata
%kirjallisuuteen, joskin se on syytä pitää taka-alalla
%– Teknistä sanastoa saa käyttää, mutta ei kaavoja tai muuta
%matemaattista notaatiota


% Bayesian models
% - What models are
% - What bayesian models do
% - Why bayesian models


% Model validation
% A survey of Bayesian predictive methods
% for model assessment, selection and
% comparison
% - Vehtarin paperista inspistä
% - Myös point predictive -jutut
% - Kans pivotal quantities
% - ero point predictionin ja muiden välillä


Predictions of sales can be used
to minimize waste and ensure sufficient supply of goods. Advertising products can yield greater sales,
but not all ads are equally effective. Shifting marketing investments to more impactfull marketing channels
can increase sales while keeping costs the same. Both of these examples demonstrate scenarios where statistical models can be used to
avoid making suboptimal decisions.

Models can be viewed as simplifications of reality. This means that no model never really matches the true data generating processes, 
but if we can formulate a model that works well enough, we can try to draw some conclusions from them. Most of the models we are concerned with
link together some explanatory variables to the measured data. The parameters of the function are learned by fitting the data to the model.
The fitted model can then be used to predict future observations if we can know the explanatory variables beforehand. The fitted model parameters
can also give insight on the behaviour of the physical world, assuming that said parameters have a sensible interpretation.

% Okei näille vois olla jotain lähteitä kans empiirisen mutuilun lisäks
Bayesian models differ from frequentist models in two major ways. Firstly, in bayesian thinking parameters are not expressed as point values but distributions.
Secondly, the distributions are affected also by the prior beliefs of the distribution. This means, that the data is not the only source of information affecting
the results. These qualities allow for embedding uncertainty and business knowledge in the models. Highly informative priors can also make the models behave more 
robustly in case the data has some outliers. 

% TODO: "Kirjallisuuskatsaus" alkaa nyt
% Yleiskuva: On tapoja, mutta kussakin on puutteita. Perustuu vahvasti siihen survey-paperiin ja understanding... paperiin
% - Käydään läpi tavat ja niiden puutteet (varotaan toistoa intron kanssa)
% - M-open ja M-closed 
Model selection methods can be categorized by the view they take on whether the considered models contain the actual data generating model. This data generating
model would be represent the actual real world process by which some events result in the observed data. M-closed view assumes that the model is present is the 
considered models. M-open view instead attempts to model the data with minimal assumptions. M-open view is more often applicable than M-closed.  

M-open methods for model selection can be further classified by reuse of data. M-open assumes that pseudo-random samples of future data can be obtained. 



\subsection{Rakenne}

\section{Datasets and methods}

%Tässä osassa kuvataan käytetty tutkimusaineisto ja tutkimuksen metodologiset
%valinnat, sekä kerrotaan tutkimuksen toteutustapa ja käytetyt menetelmät.


% Dataset perusjutut

The original dataset consists of department-level weekly sales data of 45 stores. The data spans a little over two years, from 
20.2.2010 to 26.10.2012. Each store location is associated with features that may help with sales prediction. 
The features are temperature, unemployment, price of gas, and consumer price index CPI. Also the store size
and type of store is known. The original dataset contains information about markdowns, but this feature is available only from 11.11.2011 onwards.
This renders the feature useless, as it is hard to compensate for the missing data.

The sales data for store groups A and B demonstrate strong seasonality. Especially during decembers the turnover spikes due to 
strong holiday effect. For store group C the sales seem a lot more consistent. Temperature is the only feature that clearly behaves seasonally. 
Originally unemployment was expressed to equal the latest unemployment statistic. This made the feature behave rather dincontinously. To get around
the discontinuity affecting the results, the unemployment for each week was calculated by interpolating unemployment from last and next changepoint.
After the transformation, both unemployment and consumer price index (CPI) have a clear trend. 

%Usually trends or seasonalities are an issue if they are present in the explanatory variables. Trend can cause the model to 
%intepret the feature having a too significant effect on the response variable if the trend in response variable is not caused
%by the explanatory variable. Same applies to ...
%However, this thesis focuses on 
%comparing the results of different validation metrics. The quality of the models is not a priority. 

% Dataset aggregoinnit

The original dataset contains sales data on a departement level. There are a total of 81 departements, but not all are present in every
store. We are still left with 3331 sales timeseries. Not all timeseries can be modelled of fitted, thus we need to reduce the amount of data to have any
hope of modelling anything in a reasonable time. The departement-level sales are first aggregated to store-level sales by summing sales in each departement
in each store. This still leaves us with 45 timeseries, which is still a bit too much. To simplify things a bit more, the stores are further aggregated based on
store type (A, B or C). The features for these store groups are obtained by calculating a size-weighted average. As the aggregation process of the features can 
render the features less meaningfull, a small number of stores is also selected for modelling from each store group.

% Mallit

The prophet model is a linear model used to predict time series. The model consists of seasonality components, trend, and possible explanatory variables. The 
seasonalities are modelled using a fourier approximation with a limited amount of coefficients. Trend is modelled linearly between a number of pre-determined 
changepoints. After the last change point the model also assumes a linear trend. The prophet model handles time as a feature ranging from 0 to 1. As such, 
the actual time interval between datapoints does not have to be constant.

Each of the five fitted models is an prophet model with different settings and features. The models were constructed to showcase the behaviour of the metrics
in situations where the model is used as one could use it in a business environment, overfitting seasonality, a case where a data-generating model can be constructed
from the explanatory variables, and a case similar to the last-mentioned but with even less distracting variables. The model differences are represented in table \ref{tab:model_settings}. 

% M1: Only weekly sales, no additional features.
% M2: All features, no other tricks.
% M3: The response variable is given as a explanatory variable. Perfect predictions can thus be obtained with this model.
% M4: Seasonality is modeled with 20 coefficients instead of 10.
% M5: Similar to M3, but seasonality is disabled, and trend has only one changepoint. 

\begin{table}[]
	\caption{\label{tab:model_settings} Different settings used in each model. Extra features are fuel price, CPI, unemployment and temereature.}
	\begin{tabular}{|l|l|l|l|l|l|}
		\hline
																		& \textbf{M1} & \textbf{M2} & \textbf{M3} & \textbf{M4} & \textbf{M5} \\ \hline
		Yearly seasonality coefficients & 10          & 10          & 10          & 20          & None        \\ \hline
		Extra features                  &             & X           &             &             &             \\ \hline
		Trend changepoints              & 25          & 25          & 25          & 25          & 1           \\ \hline
		Response variable as regressor  &             &             & X           &             & X           \\ \hline
		\end{tabular}
\end{table}


% Joku lörinä M-open, M-closed yms. jutuista olis aika hyvä just tässä.

% Metriikat

The models were compared using five diferent metrics. The metrics used were Akaike information criterion (AIC), deviance information criterion (DIC),
Watanabe-Aikaike information criterion (WAIC), mean average percentage error (MAPE), and 10-fold cross validation. The information criterions are calculated using only
in-sample fits. They aim to estimate the out-of-sample predictive performance of the model using the likelihood of past observations. Notably only WAIC of the information criterions
fully considers the bayesian nature of the model. It utilises the whole posterior distribution instead of some aggregated values. MAPE is calculated by reserving a 
small portion of data from the tail of the dataset to act as a test set. The percentage errors of the predictions are then averaged to obtain MAPE. 10-fold cross validation
is calculated by assigning randomly 1/10 of the datapoints as test set and then calculating the likelihood of the prediction for the test set. This is done 10 times
so that each datapoint belongs to the test set once. 10-fold CV is the average of the results.

% Miten MAPE eroaa likelihood-jutuista

% Perustelut just näiden metriikoiden valinnalle

% Perustelu 10-fold cv:n datan droppaukselle, jossa ennustetta ei lasketa yhtenäiselle ajanjaksolle






\begin{figure}[htb]
	\centering
	\includegraphics[height=8cm]{../plots/dataset/dataset_plot_y.pdf}
	\caption{Aggregated weekly sales by store group. Groups A and B demonstrate holiday effects while group C remains relatively stable through each year.
	}
	\label{fig:data_y}
\end{figure}


% https://www.overleaf.com/learn/latex/How_to_Write_a_Thesis_in_LaTeX_(Part_3):_Figures,_Subfigures_and_Tables
\begin{figure}
	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../plots/dataset/dataset_plot_temperature.pdf}
		\caption{Temperature by store group}
		\label{fig:data_temp}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../plots/dataset/dataset_plot_CPI.pdf}
		\caption{Consumer price index by store group}
		\label{fig:data_cpi}
	\end{subfigure}


	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../plots/dataset/dataset_plot_fuel_price.pdf}
		\caption{Fuel price by store group}
		\label{fig:data_fuel}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../plots/dataset/dataset_plot_unemployment_interpolated.pdf}
		\caption{Interpolated unemployment rate by store group}
		\label{fig:data_unemp}
	\end{subfigure}
\end{figure}

% \begin{figure}[htb] % Kaikkien mallien in-sample -fitit
% 	\centering
% 	\includegraphics[height=8cm]{../plots/forecasts/model_fits_aggregated_A.pdf}
% 	\caption{A concept of what another kind of prediction plot could look like. This plot shows in-sample predictions from each of the models in one dataset.}
% 	\label{fig:plot_demo_2}
% \end{figure}


\section{Results}

% – Tuloksia voi havainnollistaa kuvilla ja taulukoilla 

% – Tulosten tulkinta esittelyn yhteydessä: Mitä tulokset tarkoittavat
% tutkittavan ilmiön kannalta? Ovatko ne järkeviä? Ovatko
% esimerkiksi tulokset tilastollisesti merkittäviä?

% – Herkkyystarkastelut – miten mallin oletukset / parametrivalinnat
% vaikuttavat tuloksiin?

% Tulosluvun tulee olla ymmärrettävissä ilman syvällistä
% perehtymistä menetelmälukuun – vältä yliteknisyyttä.

% Ensin laitetaan plotit ja taulukot omille paikoilleen



% Tässä osassa esitetään tulokset ja vastataan tutkielman alussa
% esitettyihin tutkimuskysymyksiin. Tieteellisen kirjoitelman
% arvo mitataan tässä osassa esitettyjen tulosten perusteella. 

%% Huomaa seuraavassa kappaleessa lainausmerkkien ulkopuolella piste, 
%% koska piste ei lopeta lainattua tekstinpätkää.
%% Jos lainattu tekstinpätkä loppuu välimerkkiin, tulee välimerkki
%% lainausmerkkien sisälle: 
%% "Et tu, Brute?" sanoi Caesar kuollessaan.
% Tutkimustuloksien merkitystä on aina syytä arvioida ja tarkastella
% kriittisesti.  Joskus tarkastelu voi olla tässä osassa, mutta se
% voidaan myös jättää viimeiseen osaan, jolloin viimeisen osan nimeksi
% tulee >>Tarkastelu>>. Tutkimustulosten merkitystä voi arvioida myös
% >>Johtopäätökset>>-otsikon alla viimeisessä osassa. 

% Tässä osassa on syytä myös arvioida tutkimustulosten luotettavuutta.
% Jos tutkimustulosten merkitystä arvioidaan >>Tarkastelu>>-osassa,
% voi luotettavuuden arviointi olla myös siellä. 





Applying the metrics yielded promising results. The results are presented visually in figures \ref{fig:metrics_A}, 
\ref{fig:metrics_B} and \ref{fig:metrics_C}. The visual representation highlights the order different metrics rank the models.
AIC and DIC ranked all the models similarly for all the datasets, but there were differences in the margins between the models.
WAIC seemed to mostly agree with AIC and DIC, but in datasets B and C the order of models m1 and m4 was reversed. 

Ranking by MAPE has many similarities with the information criterion rankings. However the model m5 performed worse with all 
datasets, dropping behind m3 in A and C, but also behind m1 and m4 in B. In dataset B MAPE ranked m1 better than m4. This agrees
with the WAIC ranking, but it is the other way around with AIC and DIC. The other notable difference in MAPE scores is that in datasets
A and B the model m2 seems to perform much worse than the other models. However this phenomenon is not present in C. 

10-fold cross validation ranks the models m5 and m3 the best in all datasets, just like the information criterions do. However the
ranking of the rest varies. In dataset C the models m1, m2 and m4 are ranked similarly as by AIC and DIC. In both A and B the model m4
takes the last place, while m2 and m1 get a score similar to each other. M2 was ranked better than m1 for dataset A and vice versa for B, but
the margin was rather slim.

% TODO: VOIKO OLLA NIIN, ETTÄ 10-FOLD CV:SSÄ KÄY M4:N KANSSA SITEN, ETTÄ VAAN JOKU NIISTÄ FITEISTÄ MENEE TOSI PAHASTI PIELEEN???

Overall it seems, that the metrics correctly recognize the "data generating models" from other models. Also M5 mostly ranks better than M3, as it has less 
non-informative regressors. When it comes to the ranking of models M1, M2 and M4, the results are not as clear. In store groups A and B M2 performs much worse than the other models when evaluating with MAPE. This likely indicates, that the model overestimates the importance of the external regressors. As the regressors have
trends, the prediction drifts off the actual sales. In 10-fold cv this is not observed, as the datapoints in test set are picked randomly. The test points have similar-valued training points next to them, thus the trend does not have time to cause the predictions to drift off.

10-fold cv appears to rank M4 worse than the other metrics. This may be due to overfitting the seasonality with too little training data. As the model is evaluated with 10-fold cv, 10\% of the data is reserved for testing. This reduction of training data can be the cause for the model to overfit the seasonality, as it had a greater number of coefficients to fit than the other models.

% TODO: testaa molemmat yllä mainitut hypoteesit: MAPE:n ja cv:n erot, M4 overfittaus jos vaan 90% datasta käytössä

One thing to keep in mind when examining the results is the difference of loss functions used in the metrics, in particular the difference in MAPE and the others. Other metrics are based on estimating the log-likelihood of out-of-sample predictions, while MAPE evaluates the mean absolute percentage error. Log-likelihood is proportional to MSE as the model consist an normally distributed error term with a constant variance. In a perfect world the loss function would be representing the actual losses due to errors in predictions. However, it is really difficult to estimate those accurately. 


% Pohditaan syitä tuloksille 
% mitä tulokset tarkoittavat nyt sitten mallien validoinnin kannalta?
% - Onko järkevää käyttää *IC-metriikoita? Vai olisko MAPE sittenkin hyvä?
% - Muistutetaan lukijaa loss-functionin merkityksestä
% - lisätutkimus: loss-functioniks joku mapen tyyppinen, mut millä sit annetaan sakkoja?




\begin{figure}[htb]
	\centering
	\includegraphics[height=8cm]{../plots/metrics/metrics_plot_A.pdf}
	\caption{Visualization of model validation metric results applied on store group A. Arranged such that visually lower is better.
	Each axis is scaled so that extreme values are at the ends. Please note the inverted axis of 10-fold cross validation metric. For 
	precise values please refer to Table \ref{tab:metrics_A}.
	}
	\label{fig:metrics_A}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[height=8cm]{../plots/metrics/metrics_plot_B.pdf}
	\caption{Caption this}
	\label{fig:metrics_B}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[height=8cm]{../plots/metrics/metrics_plot_C.pdf}
	\caption{Caption this}
	\label{fig:metrics_C}
\end{figure}

\begin{table*}[!ht]
	\caption{\label{tab:metrics_A}Results of validation metrics applied on store group A}
\csvreader[%
	tabular={|c|c|c|c|c|c|},
				table head = \hline\textbf{Model} &\textbf{AIC} &\textbf{DIC} &\textbf{WAIC} &\textbf{MAPE}&\textbf{10-fold CV}\\\hline,
				late after line= \\,
				late after last line=\\\hline %
				]{../tables/rounded/aggregated_A_metrics.csv}{model_name=\mname,DIC=\dic,AIC=\aic,WAIC=\waic,default_cv=\MAPE,10-fold_cv=\cv}%
				{\mname & \aic & \dic & \waic & \MAPE & \cv}
				\centering
				
\end{table*}

\begin{table*}[!ht]
	\caption{\label{tab:metrics_B}Results of validation metrics applied on store group B}
\csvreader[%
	tabular={|c|c|c|c|c|c|},
				table head = \hline\textbf{Model} &\textbf{AIC} &\textbf{DIC} &\textbf{WAIC} &\textbf{MAPE}&\textbf{10-fold CV}\\\hline,
				late after line= \\,
				late after last line=\\\hline %
				]{../tables/rounded/aggregated_B_metrics.csv}{model_name=\mname,DIC=\dic,AIC=\aic,WAIC=\waic,default_cv=\MAPE,10-fold_cv=\cv}%
				{\mname & \aic & \dic & \waic & \MAPE & \cv}
				\centering
				
\end{table*}

\begin{table*}[!ht]
	\caption{\label{tab:metrics_C}Results of validation metrics applied on store group C}
	\csvreader[%
	tabular={|c|c|c|c|c|c|},
				table head = \hline\textbf{Model} &\textbf{AIC} &\textbf{DIC} &\textbf{WAIC} &\textbf{MAPE}&\textbf{10-fold CV}\\\hline,
				late after line= \\,
				late after last line=\\\hline %
				]{../tables/rounded/aggregated_C_metrics.csv}{model_name=\mname,DIC=\dic,AIC=\aic,WAIC=\waic,default_cv=\MAPE,10-fold_cv=\cv}%
				{\mname & \aic & \dic & \waic & \MAPE & \cv}
				\centering
\end{table*}

% \begin{figure}[htb] % Perus prophet-plotti, varmaan hyödytön
% 	\centering
% 	\includegraphics[height=8cm]{../plots/plot_demo.pdf}
% 	\caption{Demo of what kind of precidtion plots the Propchet package can produce
%   by default. These may be helpful (?)}
% 	\label{fig:plot_demo}
% \end{figure}



\begin{figure}[htb]
	\centering
	\includegraphics[height=8cm]{../plots/forecasts/cv_metric_demo_plot.pdf}
	\caption{Demonstrating the cv metric calculation}
	\label{fig:cv_demo}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[height=8cm]{../plots/forecasts/30_weeks_prediction_demo.pdf}
	\caption{A prediction 30 weeks in the future. Training data in black, test data in red.}
	\label{fig:prediction_demo}
\end{figure}

\begin{figure}[htb]
	\centering
	\includegraphics[height=8cm]{../plots/forecasts/30_weeks_prediction_components_demo.pdf}
	\caption{Components of the fitted model used in figure \ref{fig:prediction_demo}}
	\label{fig:prediction_components_demo}
\end{figure}





%\csvautotabular{../tables/single_store_4_of_A_metrics.csv}
%\section{Yhteenveto}
\section{Summary} 

%Opinnäytteen tekijä vastaa siitä, että opinnäyte on tässä dokumentissa
%ja opinnäytteen tekemistä käsittelevillä luennoilla sekä
%harjoituksissa annettujen ohjeiden mukainen muotoseikoiltaan,
%rakenteeltaan ja ulkoasultaan.




% LÄHDELUETTELO
%  BibTeX-tiedoston kokoaminen onnistuu näppärästi esim. 
%  Firefoxin Zotero-lisäosalla http://www.zotero.org/
%  joka osaa poimia viitteet suoraan Google Scholarista.



% Ladataan library.bib
\bibliography{library}


%% Liitteet
%% Poista a.o. \clearpage- ja \thesisappendix -makrot, jos liiteitä ei ole.
\clearpage
\thesisappendix

\section{Esimerkki liitteestä\label{LiiteA}}

%Kaavojen numerointi muodostaa liitteissä oman kokonaisuutensa:
%\begin{align}
%d \wedge A &= F, \label{liitekaava1}\\
%d \wedge F &= 0. \label{liitekaava2}
%\end{align}


\clearpage
\section{Toinen esimerkki liitteestä\label{LiiteB}}

%% Liitteiden kaavat, taulukot ja kuvat numeroidaan omana kokonaisuutenaan

% Liitteissä voi myös olla kuvia, jotka
% eivät sovi leipätekstin joukkoon:
%% Ympäristön figure parametrit htb pakottavat
%% kuvan tähän, eikä LaTeX yritä siirrellä niitä
%% hyväksi katsomaansa paikkaan. 
%% Ympäristöä center voi käyttää \centering-
%% komennon sijaan
%%

%%
% Liitteiden taulukoiden numerointi on kuvien ja kaavojen kaltainen:
% \begin{table}[htb]
% \caption{Taulukon kuvateksti.}
% \label{liitetaulukko}
% \centering
% \fbox{
% \begin{tabular}{lp{0.5\linewidth}}
% 9.00--9.55  & Käytettävyystestauksen tiedotustilaisuus (osanottajat
% ovat saaneet sähköpostitse valmistautumistehtävät, joten tiedotustilaisuus
% voidaan pitää lyhyenä).\\
% 9.55--10.00 & Testausalueelle siirtyminen
% \end{tabular}}
% \end{table}
% Kaavojen numerointi muodostaa liitteissä oman kokonaisuutensa:
% \begin{align}
% T_{ik} &= -p g_{ik} + w u_i u_k + \tau_{ik},  \label{liitekaava3} \\
% n_i    &= n u_i + v_i.                      \label{liitekaava4}
% \end{align}

\end{document}
